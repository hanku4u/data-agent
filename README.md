# Data Agent ðŸ¤–ðŸ“Š

Pluggable AI agent for data fetching, transformation, and chart generation. Built with [Pydantic AI](https://github.com/pydantic/pydantic-ai), FastAPI, and Plotly.

[![CI](https://github.com/hanku4u/data-agent/actions/workflows/ci.yml/badge.svg)](https://github.com/hanku4u/data-agent/actions/workflows/ci.yml)

## Features

- **Multi-source data fetching** â€” CSV, JSON, SQL databases, REST APIs
- **AI-powered queries** â€” Natural language data exploration via Pydantic AI agents
- **Chart generation** â€” Line, bar, scatter, and area charts with Plotly
- **Data transformations** â€” GroupBy, resample, rolling averages, aggregations
- **Structured logging** â€” JSON-formatted logs with structlog
- **Error handling** â€” Custom exception hierarchy with proper HTTP status mapping
- **Source validation** â€” Validates data source configs before registration
- **SQL injection protection** â€” Parameterized queries and column whitelisting

## Quick Start

```bash
# Install
pip install -e ".[dev]"

# Configure (copy and edit)
cp .env.example .env

# Run the API server
uvicorn data_agent.api:app --reload
```

## Configuration

Set environment variables or use a `.env` file:

```env
LLM_PROVIDER=ollama
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=qwen3:8b
SOURCES_CONFIG=./sources.yaml
```

## API Endpoints

| Method | Path | Description |
|--------|------|-------------|
| `GET` | `/health` | Health check |
| `POST` | `/agent/query` | Query the AI agent |
| `GET` | `/data-sources` | List registered sources |
| `POST` | `/data-sources` | Register a new source |
| `GET` | `/data-sources/{name}/schema` | Get source schema |
| `DELETE` | `/data-sources/{name}` | Remove a source |
| `POST` | `/agent/chart` | Generate a chart directly |

## Usage Examples

### Register a CSV source

```bash
curl -X POST http://localhost:8000/data-sources \
  -H "Content-Type: application/json" \
  -d '{"name": "metrics", "type": "csv", "config": {"path": "./data/sample_metrics.csv"}}'
```

### Query the agent

```bash
curl -X POST http://localhost:8000/agent/query \
  -H "Content-Type: application/json" \
  -d '{"query": "Show me a line chart of cpu_usage over time from the metrics source"}'
```

### YAML source configuration

Define sources in `sources.yaml`:

```yaml
sources:
  sales:
    type: csv
    config:
      path: ./data/sales.csv
    description: Monthly sales data

  analytics_db:
    type: sql
    config:
      connection_string: sqlite:///./data/analytics.db
      table: events
    description: Analytics events
```

## Data Transformations

The agent can perform data transformations before charting:

- **groupby** â€” Group by columns with sum/mean/count/min/max
- **resample** â€” Resample time-series (D/W/M/Q/Y frequencies)
- **rolling_average** â€” Moving averages with configurable window
- **aggregate** â€” Single-value computations (sum, mean, std, etc.)

## Architecture

```
src/data_agent/
â”œâ”€â”€ agent.py          # Pydantic AI agent with tools
â”œâ”€â”€ api.py            # FastAPI application
â”œâ”€â”€ config.py         # Pydantic Settings configuration
â”œâ”€â”€ dependencies.py   # FastAPI dependency injection
â”œâ”€â”€ exceptions.py     # Custom exception hierarchy
â”œâ”€â”€ log.py            # Structured logging (structlog)
â”œâ”€â”€ middleware.py      # Error handler & request logging
â”œâ”€â”€ models.py         # Pydantic request/response models
â”œâ”€â”€ registry.py       # Source registry
â”œâ”€â”€ charts/
â”‚   â””â”€â”€ engine.py     # Plotly chart generation
â”œâ”€â”€ sources/
â”‚   â”œâ”€â”€ base.py       # Abstract DataSource
â”‚   â”œâ”€â”€ csv_source.py # CSV/JSON file source
â”‚   â”œâ”€â”€ sql_source.py # SQL database source
â”‚   â””â”€â”€ api_source.py # REST API source
â””â”€â”€ tools/
    â”œâ”€â”€ fetch.py      # Data fetch tool
    â”œâ”€â”€ chart.py      # Chart generation tool
    â””â”€â”€ transform.py  # Data transformation tool
```

## Testing

```bash
# Run all tests
python -m pytest tests/ -v

# Run specific phase
python -m pytest tests/test_phase0.py -v
```

## License

MIT
